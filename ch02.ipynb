{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "This notebook contains all Python files from ch02 directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nfrom common.util import preprocess, create_co_matrix, cos_similarity\n\n\ntext = 'You say goodbye and I say hello.'\ncorpus, word_to_id, id_to_word = preprocess(text)\nvocab_size = len(word_to_id)\nC = create_co_matrix(corpus, vocab_size)\n\nc0 = C[word_to_id['you']]  #「you」の単語ベクトル\nc1 = C[word_to_id['i']]  #「i」の単語ベクトル\nprint(cos_similarity(c0, c1))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## most_similar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nfrom common.util import preprocess, create_co_matrix, most_similar\n\n\ntext = 'You say goodbye and I say hello.'\ncorpus, word_to_id, id_to_word = preprocess(text)\nvocab_size = len(word_to_id)\nC = create_co_matrix(corpus, vocab_size)\n\nmost_similar('you', word_to_id, id_to_word, C, top=5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_method_big.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nimport numpy as np\nfrom common.util import most_similar, create_co_matrix, ppmi\nfrom dataset import ptb\n\n\nwindow_size = 2\nwordvec_size = 100\n\ncorpus, word_to_id, id_to_word = ptb.load_data('train')\nvocab_size = len(word_to_id)\nprint('counting  co-occurrence ...')\nC = create_co_matrix(corpus, vocab_size, window_size)\nprint('calculating PPMI ...')\nW = ppmi(C, verbose=True)\n\nprint('calculating SVD ...')\ntry:\n    # truncated SVD (fast!)\n    from sklearn.utils.extmath import randomized_svd\n    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n                             random_state=None)\nexcept ImportError:\n    # SVD (slow)\n    U, S, V = np.linalg.svd(W)\n\nword_vecs = U[:, :wordvec_size]\n\nquerys = ['you', 'year', 'car', 'toyota']\nfor query in querys:\n    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_method_small.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom common.util import preprocess, create_co_matrix, ppmi\n\n\ntext = 'You say goodbye and I say hello.'\ncorpus, word_to_id, id_to_word = preprocess(text)\nvocab_size = len(id_to_word)\nC = create_co_matrix(corpus, vocab_size, window_size=1)\nW = ppmi(C)\n\n# SVD\nU, S, V = np.linalg.svd(W)\n\nnp.set_printoptions(precision=3)  # 有効桁３桁で表示\nprint(C[0])\nprint(W[0])\nprint(U[0])\n\n# plot\nfor word, word_id in word_to_id.items():\n    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\nplt.scatter(U[:,0], U[:,1], alpha=0.5)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ppmi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nimport numpy as np\nfrom common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n\n\ntext = 'You say goodbye and I say hello.'\ncorpus, word_to_id, id_to_word = preprocess(text)\nvocab_size = len(word_to_id)\nC = create_co_matrix(corpus, vocab_size)\nW = ppmi(C)\n\nnp.set_printoptions(precision=3)  # 有効桁３桁で表示\nprint('co-occurrence matrix')\nprint(C)\nprint('-'*50)\nprint('PPMI')\nprint(W)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_ptb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# coding: utf-8\nfrom dataset import ptb\n\n\ncorpus, word_to_id, id_to_word = ptb.load_data('train')\n\nprint('corpus size:', len(corpus))\nprint('corpus[:30]:', corpus[:30])\nprint()\nprint('id_to_word[0]:', id_to_word[0])\nprint('id_to_word[1]:', id_to_word[1])\nprint('id_to_word[2]:', id_to_word[2])\nprint()\nprint(\"word_to_id['car']:\", word_to_id['car'])\nprint(\"word_to_id['happy']:\", word_to_id['happy'])\nprint(\"word_to_id['lexus']:\", word_to_id['lexus'])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}